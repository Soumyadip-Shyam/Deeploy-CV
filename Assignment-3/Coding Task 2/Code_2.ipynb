{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T10:55:49.374859Z",
     "start_time": "2024-12-22T10:55:37.874311Z"
    }
   },
   "cell_type": "code",
   "source": "pip install annoy",
   "id": "1b66384fcc025262",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting annoy\r\n",
      "  Downloading annoy-1.17.3.tar.gz (647 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m647.5/647.5 kB\u001B[0m \u001B[31m8.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hBuilding wheels for collected packages: annoy\r\n",
      "  Building wheel for annoy (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for annoy: filename=annoy-1.17.3-cp312-cp312-macosx_10_12_universal2.whl size=112740 sha256=66374e615f043042b27a95f146b7a222b003838b47b9b05b46576d35ffb27067\r\n",
      "  Stored in directory: /Users/soumyadip_iitk/Library/Caches/pip/wheels/db/b9/53/a3b2d1fe1743abadddec6aa541294b24fdbc39d7800bc57311\r\n",
      "Successfully built annoy\r\n",
      "Installing collected packages: annoy\r\n",
      "Successfully installed annoy-1.17.3\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-22T12:39:55.370558Z",
     "start_time": "2024-12-22T12:39:53.253574Z"
    }
   },
   "source": [
    "from importlib.metadata import metadata\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import torch.nn as nn\n",
    "from annoy import AnnoyIndex"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T12:00:08.839499Z",
     "start_time": "2024-12-22T12:00:08.819692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "images_file = '/Users/soumyadip_iitk/PycharmProjects/<231026>_<Soumyadip>_deeploycv/untitled folder/Dog'\n",
    "images = os.listdir(images_file)\n",
    "print(len(images))"
   ],
   "id": "c53eefffe2ea6e2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12499\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T12:00:09.711676Z",
     "start_time": "2024-12-22T12:00:09.376836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weights = models.ResNet18_Weights.IMAGENET1K_V1\n",
    "model = models.resnet18(weights=weights)\n",
    "model.fc = nn.Identity()\n",
    "print(model)"
   ],
   "id": "c4b09e5c8848e542",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T12:00:10.004246Z",
     "start_time": "2024-12-22T12:00:09.998343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n"
   ],
   "id": "e8b28cf3e7c67484",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T12:00:10.613870Z",
     "start_time": "2024-12-22T12:00:10.602639Z"
    }
   },
   "cell_type": "code",
   "source": "annoy_index = AnnoyIndex(512,'angular')",
   "id": "6e0e0773b06c3539",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T12:04:31.639565Z",
     "start_time": "2024-12-22T12:00:11.224913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(len(images)):\n",
    "    image = Image.open(os.path.join(images_file, images[i]))\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "    if input_tensor.size()[1] == 3:\n",
    "        output_tensor = model(input_tensor)\n",
    "        # print(f'{i} predicted as {output_tensor.size()} predicted as {weights.meta[\"categories\"][torch.argmax(output_tensor)]}')\n",
    "        # input()\n",
    "        #print(output_tensor.shape())\n",
    "        annoy_index.add_item(i, output_tensor[0])\n",
    "        if i%100==0 & i!=11702:\n",
    "            print(f'We have processed {i} images.')\n",
    "\n",
    "annoy_index.build(10) #10 number of trees\n",
    "annoy_index.save('dog.ann')"
   ],
   "id": "a90a1a00cf4d4dd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have processed 0 images.\n",
      "We have processed 100 images.\n",
      "We have processed 200 images.\n",
      "We have processed 300 images.\n",
      "We have processed 400 images.\n",
      "We have processed 500 images.\n",
      "We have processed 600 images.\n",
      "We have processed 700 images.\n",
      "We have processed 800 images.\n",
      "We have processed 900 images.\n",
      "We have processed 1000 images.\n",
      "We have processed 1100 images.\n",
      "We have processed 1200 images.\n",
      "We have processed 1300 images.\n",
      "We have processed 1400 images.\n",
      "We have processed 1500 images.\n",
      "We have processed 1600 images.\n",
      "We have processed 1700 images.\n",
      "We have processed 1800 images.\n",
      "We have processed 1900 images.\n",
      "We have processed 2000 images.\n",
      "We have processed 2100 images.\n",
      "We have processed 2200 images.\n",
      "We have processed 2300 images.\n",
      "We have processed 2400 images.\n",
      "We have processed 2500 images.\n",
      "We have processed 2600 images.\n",
      "We have processed 2700 images.\n",
      "We have processed 2800 images.\n",
      "We have processed 2900 images.\n",
      "We have processed 3000 images.\n",
      "We have processed 3100 images.\n",
      "We have processed 3200 images.\n",
      "We have processed 3300 images.\n",
      "We have processed 3400 images.\n",
      "We have processed 3500 images.\n",
      "We have processed 3600 images.\n",
      "We have processed 3700 images.\n",
      "We have processed 3800 images.\n",
      "We have processed 3900 images.\n",
      "We have processed 4000 images.\n",
      "We have processed 4100 images.\n",
      "We have processed 4200 images.\n",
      "We have processed 4300 images.\n",
      "We have processed 4400 images.\n",
      "We have processed 4500 images.\n",
      "We have processed 4600 images.\n",
      "We have processed 4700 images.\n",
      "We have processed 4800 images.\n",
      "We have processed 4900 images.\n",
      "We have processed 5000 images.\n",
      "We have processed 5100 images.\n",
      "We have processed 5200 images.\n",
      "We have processed 5300 images.\n",
      "We have processed 5400 images.\n",
      "We have processed 5500 images.\n",
      "We have processed 5600 images.\n",
      "We have processed 5700 images.\n",
      "We have processed 5800 images.\n",
      "We have processed 5900 images.\n",
      "We have processed 6000 images.\n",
      "We have processed 6100 images.\n",
      "We have processed 6200 images.\n",
      "We have processed 6300 images.\n",
      "We have processed 6400 images.\n",
      "We have processed 6500 images.\n",
      "We have processed 6600 images.\n",
      "We have processed 6700 images.\n",
      "We have processed 6800 images.\n",
      "We have processed 6900 images.\n",
      "We have processed 7000 images.\n",
      "We have processed 7100 images.\n",
      "We have processed 7200 images.\n",
      "We have processed 7300 images.\n",
      "We have processed 7400 images.\n",
      "We have processed 7500 images.\n",
      "We have processed 7600 images.\n",
      "We have processed 7700 images.\n",
      "We have processed 7800 images.\n",
      "We have processed 7900 images.\n",
      "We have processed 8000 images.\n",
      "We have processed 8100 images.\n",
      "We have processed 8200 images.\n",
      "We have processed 8300 images.\n",
      "We have processed 8400 images.\n",
      "We have processed 8500 images.\n",
      "We have processed 8600 images.\n",
      "We have processed 8700 images.\n",
      "We have processed 8800 images.\n",
      "We have processed 8900 images.\n",
      "We have processed 9000 images.\n",
      "We have processed 9100 images.\n",
      "We have processed 9200 images.\n",
      "We have processed 9300 images.\n",
      "We have processed 9400 images.\n",
      "We have processed 9500 images.\n",
      "We have processed 9600 images.\n",
      "We have processed 9700 images.\n",
      "We have processed 9800 images.\n",
      "We have processed 9900 images.\n",
      "We have processed 10000 images.\n",
      "We have processed 10100 images.\n",
      "We have processed 10200 images.\n",
      "We have processed 10300 images.\n",
      "We have processed 10400 images.\n",
      "We have processed 10500 images.\n",
      "We have processed 10600 images.\n",
      "We have processed 10700 images.\n",
      "We have processed 10800 images.\n",
      "We have processed 10900 images.\n",
      "We have processed 11000 images.\n",
      "We have processed 11100 images.\n",
      "We have processed 11200 images.\n",
      "We have processed 11300 images.\n",
      "We have processed 11400 images.\n",
      "We have processed 11500 images.\n",
      "We have processed 11600 images.\n",
      "We have processed 11700 images.\n",
      "We have processed 11800 images.\n",
      "We have processed 11900 images.\n",
      "We have processed 12000 images.\n",
      "We have processed 12100 images.\n",
      "We have processed 12200 images.\n",
      "We have processed 12300 images.\n",
      "We have processed 12400 images.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d9926c74c8704f8f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***Building Annoy Index***",
   "id": "7553ac9568dd83e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T12:36:10.016551Z",
     "start_time": "2024-12-22T12:24:59.650948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_grid = Image.new('RGB', (1000,1000))\n",
    "for i in range(len(images)):\n",
    "    image = Image.open(os.path.join(images_file, images[i]))\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "    if input_tensor.size()[1] == 3:\n",
    "        output_tensor = model(input_tensor)\n",
    "        nns = annoy_index.get_nns_by_vector(output_tensor[0], 24)\n",
    "        image = image.resize((200,200))\n",
    "        image_draw = ImageDraw.Draw(image)\n",
    "        image_draw.rectangle([(0,0),(199,199)],outline='red',width=8)\n",
    "        image_grid.paste(image,(0,0))\n",
    "\n",
    "        for j in range(24):\n",
    "            search_image = Image.open(os.path.join(images_file, images[nns[j]]))\n",
    "            search_image = search_image.resize((200,200))\n",
    "            image_grid.paste(search_image,((200*((j+1)%5),200*((j+1)//5))))\n",
    "\n",
    "    image_grid.save(f'Image_dump/image_{i}.png')"
   ],
   "id": "9fbec44839ba46c3",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/<231026>_<Soumyadip>_deeploycv/.venv/lib/python3.12/site-packages/PIL/ImageFile.py:554\u001B[0m, in \u001B[0;36m_save\u001B[0;34m(im, fp, tile, bufsize)\u001B[0m\n\u001B[1;32m    553\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 554\u001B[0m     fh \u001B[38;5;241m=\u001B[39m \u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfileno\u001B[49m()\n\u001B[1;32m    555\u001B[0m     fp\u001B[38;5;241m.\u001B[39mflush()\n",
      "\u001B[0;31mAttributeError\u001B[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[71], line 19\u001B[0m\n\u001B[1;32m     16\u001B[0m         search_image \u001B[38;5;241m=\u001B[39m search_image\u001B[38;5;241m.\u001B[39mresize((\u001B[38;5;241m200\u001B[39m,\u001B[38;5;241m200\u001B[39m))\n\u001B[1;32m     17\u001B[0m         image_grid\u001B[38;5;241m.\u001B[39mpaste(search_image,((\u001B[38;5;241m200\u001B[39m\u001B[38;5;241m*\u001B[39m((j\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m%\u001B[39m\u001B[38;5;241m5\u001B[39m),\u001B[38;5;241m200\u001B[39m\u001B[38;5;241m*\u001B[39m((j\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m5\u001B[39m))))\n\u001B[0;32m---> 19\u001B[0m \u001B[43mimage_grid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mImage_dump/image_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mi\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.png\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/<231026>_<Soumyadip>_deeploycv/.venv/lib/python3.12/site-packages/PIL/Image.py:2605\u001B[0m, in \u001B[0;36mImage.save\u001B[0;34m(self, fp, format, **params)\u001B[0m\n\u001B[1;32m   2602\u001B[0m     fp \u001B[38;5;241m=\u001B[39m cast(IO[\u001B[38;5;28mbytes\u001B[39m], fp)\n\u001B[1;32m   2604\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 2605\u001B[0m     \u001B[43msave_handler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2606\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   2607\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m open_fp:\n",
      "File \u001B[0;32m~/PycharmProjects/<231026>_<Soumyadip>_deeploycv/.venv/lib/python3.12/site-packages/PIL/PngImagePlugin.py:1488\u001B[0m, in \u001B[0;36m_save\u001B[0;34m(im, fp, filename, chunk, save_all)\u001B[0m\n\u001B[1;32m   1484\u001B[0m     single_im \u001B[38;5;241m=\u001B[39m _write_multiple_frames(\n\u001B[1;32m   1485\u001B[0m         im, fp, chunk, mode, rawmode, default_image, append_images\n\u001B[1;32m   1486\u001B[0m     )\n\u001B[1;32m   1487\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m single_im:\n\u001B[0;32m-> 1488\u001B[0m     \u001B[43mImageFile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_save\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1489\u001B[0m \u001B[43m        \u001B[49m\u001B[43msingle_im\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mIO\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mbytes\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_idat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1491\u001B[0m \u001B[43m        \u001B[49m\u001B[43m[\u001B[49m\u001B[43mImageFile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Tile\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mzip\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43msingle_im\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrawmode\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1492\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1494\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info:\n\u001B[1;32m   1495\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m info_chunk \u001B[38;5;129;01min\u001B[39;00m info\u001B[38;5;241m.\u001B[39mchunks:\n",
      "File \u001B[0;32m~/PycharmProjects/<231026>_<Soumyadip>_deeploycv/.venv/lib/python3.12/site-packages/PIL/ImageFile.py:558\u001B[0m, in \u001B[0;36m_save\u001B[0;34m(im, fp, tile, bufsize)\u001B[0m\n\u001B[1;32m    556\u001B[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001B[1;32m    557\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mAttributeError\u001B[39;00m, io\u001B[38;5;241m.\u001B[39mUnsupportedOperation) \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m--> 558\u001B[0m     \u001B[43m_encode_tile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbufsize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(fp, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflush\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    560\u001B[0m     fp\u001B[38;5;241m.\u001B[39mflush()\n",
      "File \u001B[0;32m~/PycharmProjects/<231026>_<Soumyadip>_deeploycv/.venv/lib/python3.12/site-packages/PIL/ImageFile.py:584\u001B[0m, in \u001B[0;36m_encode_tile\u001B[0;34m(im, fp, tile, bufsize, fh, exc)\u001B[0m\n\u001B[1;32m    581\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m exc:\n\u001B[1;32m    582\u001B[0m     \u001B[38;5;66;03m# compress to Python file-compatible object\u001B[39;00m\n\u001B[1;32m    583\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 584\u001B[0m         errcode, data \u001B[38;5;241m=\u001B[39m \u001B[43mencoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbufsize\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m:]\n\u001B[1;32m    585\u001B[0m         fp\u001B[38;5;241m.\u001B[39mwrite(data)\n\u001B[1;32m    586\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m errcode:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "beff836090b10835"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
